%%
%%  Example paper
%%
%%

%%%%%%%%%%%%%%%%%% Usenix style %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[10pt,twocolumn,a4paper]{article}
\usepackage{styles/usenix-style}

\author{Jakob Schmid}

%%%%%%%%%%%%%%%%%% Document %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% TODO: Change draft to final before submitting final version.
\usepackage[draft]{styles/ka-style}
\usepackage{cite,xspace,ifthen,graphicx,listings,url}
\usepackage[inkscapeformat=pdf]{svg}

\usepackage[
   pdfauthor={Author},
   pdftitle={A Paper Template},
   pdfsubject={Paper Template},
   pdfkeywords={Papers, Templates}
]{hyperref}

\hbadness 10001

\begin{document}

\title{Unikernel Linux (UKL)}

\newcommand{\todo}[1]{{\texttt{[#1]}}}
\newcommand{\code}[1]{{\tt \small{#1}}}
\newcommand{\refsec}[1]{{ยง~\ref{#1}}}

\maketitle
%\draftfooter

\begin{abstract}
  This report discusses Unikernel Linux (UKL), an approach to introduce a
  unikernel target into the Linux kernel.
  The specialized demand of cloud services has recently given rise
  to a resurgence of library operating systems in the form of unikernels.
  The authors of the UKL paper want to show that the Linux kernel can be
  modified to include the benefits of unikernels, while maintaining the
  ecosystem of applications and maintainers of Linux.
\end{abstract}

\section{Introduction}\label{sec:introduction}
  Modern cloud services are often highly specialised, to the point of a microservice.
  In a mircoservice architecture, an application is split up into a collection of loosely coupled services,
  that communicate through lightweight protocols and each only fullfill a single purpose.
  These services share a few key demands. They need to be able to communicate 
  efficiently with each other. Since they need to communicate with other services,
  they are exposed to the internet to some degree and thus should be as secure as possible.
  Due to the single purpose nature of the microservices they often execute as a single process.
  Lastly, the image the service is executed with and the memory usage should be as small as possible.
  The services are often executed in a virtual machine on rented hardware, so lower requirements
  in memory and storage can improve the profitability of a service.
  These demands have caused a resurgence of research exploring the concept of 
  a library operating system (libOS) and the emergence of unikernels. 

  In a libOS a target application is linked with a set of
  libraries that provide all the services a regular OS would usually provide.
  The resulting executable can then be deployed directly to hardware.
  In 2013 the term \textit{unikernel} was first introduced for libOSs
  for cloud services and deployment to virtual hardware~\cite{madhavapeddy13}.

  Since then multiple unikernels have been created. Some are written from scratch like
  ClickOS \cite{martins2014} and Unikraft \cite{kuenzer21}.
  Others borrow code from an existing OS like Drawbridge \cite{porter11} 
  that uses code from Windows.

  UKL uses the Linux kernel as a base to create a unikernel.
  In the base model a target application can be statically linked and compiled with
  the modified Linux kernel into a bootable image.
  On top of the base model configuration options can be enabled to increase the performance
  for the specific application.
  For maximal specialisation, the application itself can be modified to use kernel routines
  directly.
  UKL tries to keep the changes to the Linux kernel as minimal as possible,
  so that UKL can be maintained with the (general purpose) Linux kernel.
  

\section{Background}\label{sec:background}
  \subsection{General-purpose monolithic operating systems}
    In a general-purpose monolithic operating system, such as Linux and Windows,
    the operating system (OS) defines an interface to use the physical resources
    of the system. 
    This interface hides details about the physical resources behind
    high-level abstractions like processes, files, address spaces 
    and interprocess communication.
    Applications running on the system use this interface and its abstractions
    to utilize the physical resources of the system.

    System calls are used to request the services.
    Before the requested service is executed, the OS performs a switch to a kernel thread
    to service the request.
    This is done to prevent the application from influencing the execution of the system service.
    After the system service has finished, the OS switches execution back to the application thread.

    The implementation of the service abstractions must be general to allow the execution 
    of very different applications.
    The OS also ensures that different applications can execute concurrently, 
    without interfering with each other. 
    Virtual address spaces are used to allow for simultaneous usage of physical memory.
    Access to other resources, such as files and network communication, is controlled
    by the OS.
    This protection requires that applications must not be able
    to modify or replace the implementation of the abstractions supplied by the OS.


  \subsection{Library operating systems}\label{sec:libOS}
    One of the problems of the fixed abstractions for system resources in general-purpose OSs
    is that it denies applications the advantage of domain-specific optimizations.
    For example in 1994 Cao et al. \cite{cao94} showed that application-controlled file caching
    can reduce application running time by 45\%.

    In the mid 1990s the libOS was proposed as a different OS architecture
    where the application can control the hardware abstractions, instead of the OS \cite{engler95}.
    In a libOS the hardware resources are not controlled and protected by a kernel.
    Instead a set of application-level libraries implement the mechanisms to drive hardware,
    communicate over the network and all other functionality a general-purpose 
    operating system would provide for an application.
    Further a set of policies are used to enforce access control and isolation in the
    application layer \cite{madhavapeddy13-2}.
    
    The libOS architecture allows applications to access hardware resources directly
    thus eliminating the need for repeated privilege transitions to move data
    between kernel and user space.
    In addition applications can now choose a library to drive the hardware that is
    taylored to the needs of that specific application, thus improving performance.
    This architecture also makes the performance more predictable.
    In a monolithic OS the kernel might schedule a different process after a
    context switch or do signal handling before handing control back to the application.

    Compiling an application with only the libraries the application requires
    can significantly reduce the amount of code involved.
    This reduction in code can not only lead to a reduction in image size, 
    but can also decrease the chance of the code containing a 
    security vulnerability \cite{madhavapeddy13}.

    The libOS architecture has two major disadvantages:   
    One, it is hard to achieve strong resource isolation because not all
    usage of hardware resources has to go through one abstraction supplied by
    a kernel like in a monolithic OS.
    Two, device drivers have to be rewritten to work as a library rather than
    for example a kernel module.
    This implementation effort has caused problems with hardware compatability
    for libOS projects and thus mostly limited their relevance to the
    research domain \cite{madhavapeddy13, raza19}.

  \subsection{Unikernels}
    OS virtualisation can overcome both of the major disadvantages of libOSs
    mentioned in \refsec{sec:libOS}.
    The lack of resource isolation between applications can be avoided by
    dedicating a seperate virtual machine (VM) to each application.
    This delegates resource isolation from the OS level to the hypervisor.
    The hypervisor offers a much simpler, less fine grained interface than
    a conventional OS, consisting of virtual CPUs and memory pages, 
    rather than the process-oriented approach in conventional OSs \cite{madhavapeddy13-2}.
    Dedicating a seperate VM to each application also leaves more room
    to specialize the VM to its particular purpose.
    The problem of hardware compatability of libOSs can also be overcome
    with virtualization. The libOS only has to implement drivers for
    the virtual hardware devices offered by the hypervisor.
    The hypervisor is then responsible for driving the ever changing physical
    hardware.

    Madhavapeddy et al. introduced the term unikernel in a paper 
    published in 2013 \cite{madhavapeddy13}.
    Here unikernels are described as an approach to deploy cloud services
    using specialised single-purpose libOS VMs running directly 
    on the hypervisor \cite{madhavapeddy13}.

    Despite the benefits of the unikernel approach, they have not yet been widely adopted
    outside of the research and experimental domain.
    This could be attributed to the engeneering burden of porting existing software
    to an environment with no or only partial support for legacy software interfaces \cite{raza19}.
    
    \subsubsection{Performance and size}
      Deploying a service using a unikernel can offer significant
      performance advantages.
      Typical optimisations other than using libraries specialised for the given
      application inlcude avoiding ring transition overheads \cite{maeda2003},
      leveraging the single address space to pass pointers rather than copying data \cite {schatzberg16},
      deferring preemption in latency sensitive routines,
      exploiting application knowledge to remove code that is never executed \cite{madhavapeddy13},
      and cross layer optimization between kernel and application code \cite{raza19}.

      Memcached running on a unikernel TCP/IP stack
      demonstrated a 200\% throughput improvement compared to Linux \cite{schatzberg16},
      unikernels deployed within a microVM have shown six to ten times shorter
      boot times over containers \cite{koller17} and a micropython unikernel reached an image
      size of 1~MB while requireing 8~MB of memory to run \cite{manco17}.

    \subsubsection{Threat model}\label{sec:thread-model}
      Unikernels are per definition concerned with applications that provide network
      facing services. 
      The focus on virtual hardware and deployment to a hypervisor
      often implies usage in a multi-tenant datacenter.
      Here the provider of the datacenter is trusted not to be malisious.
      Other tenants and internet-connected hosts in general are seen as 
      a potential attacker.
      Internally the hypervisor is used as the sole unit of isolation, 
      rather than adopting a multi-user access control model as most general purpose OSs do.
      External entities the unikernel communicates with are trusted through
      protocol libraries such as SSL or SSH \cite{madhavapeddy13}.

    \subsubsection{Security}
      A problem with images based on a general purpose OSs is that misconfiguration can
      leave unneeded or unnecessary services running. 
      These services can significantly increase the remote attack surface.
      When creating an appliance using the unikernel approach only the libraries
      needed by the particular application are included in the final image.
      Thus no unnecessary services are included in the final image.
      Further this can also drastically deacrease the amount of code included and thus the chance
      for a vulnerability in the code.
      
      About 70\% of vulnerabilities in Windows, a general purpose OS written in C/C++,
      that Microsoft assigns a CVE to each year are memory safety issues \cite{msrc-19-07}.
      Unikernels written in high level programming languages with a strong type system 
      can use high level language features for memory management to negate a large
      portion of these vulnerabilities \cite{madhavapeddy13, lankes19}.
      MirageOS \cite{madhavapeddy13}, a unikernel written in OCaml, can be sealed \cite{hunt07} at runtime,
      thus preventing any code not present at compile time from being executed.
      MirageOS further implements compile-time address space randomization to defend against
      return-oriented programming attacks and save on runtime complexity.
      This is justified by the fact that for unikernels reconfiguring the appliance 
      means recompiling it, potentially for every deployment \cite{madhavapeddy13}.

      Another aspect of unikernel security is that the chance for a common exploit is lower.
      An exploit found in the Linux kernel can potentially affect all machines running Linux
      due to them sharing a vast majority of their code.
      Each unikernel however is specialized to suit the needs of only one application thus
      sharing less code with other appliances using the same unikernel.
      The smaller amount of shared code decreases the probability of an exploit being applicable
      to many unikernel appliances.

    \subsubsection{Categorisation of unikernels}\label{sec:categories-of-unikernels}
      \textit{Clean slate} unikernels are written from scratch.
      Here the unikernel designers have full control over the language
      and the methodology used \cite{raza19}.
      Thus the unikernel can be specialised to an abitrary degree to service the needs
      of a particular class of applications.
      The interface available to the application can also be choosen freely.

      In \textit{strip down} unikernels an existing kernel code base is forked
      and all functionality not needed for the unikernel is removed.
      The interfaces and general purpose libraries can be perserved to some degree
      to make porting of existing applications written for the original kernel
      over to the unikernel easier. 
      This generality however comes at the cost of loosing room for specialisation,
      efficient pathways and fine-tuned implementation.
      The creation of an out-of-tree fork of an existing OS comes with the burden of
      having to manually port updates from the original OS to the unikernel at regular intervals
      in order to keep the support for existing applications \cite{raza19}.
      
\section{Related Work}\label{sec:relwork} 
  \subsection{Kernel Mode Linux}
    Kernel Mode Linux (KML) is an operating system that allows
    execution of user processes in kernel mode on IA-32 CPUs.
    Based on the observation that system calls can be 36 times slower
    than function calls \cite{maeda2003} KML allows applications to execute in
    kernel mode, thus allowing the usage of function calls instead of system calls.
    An application executing in kernel mode would be capable of accessing kernel
    memory and compromise the integrity of the system.
    To prevent this KML uses TALx86 a typed assembly language.
    The authors of KML prove that using the typed assembly language guarantees the 
    same amount of safety as using traditional hardware-based protection of the kernel \cite{maeda2003}.
    In order to benefit from that safety applications for KML have to be written in
    either TALx86 or Popcorn, a safe dialect of the C programming language.
    Here instead of using system calls the programmer can now use function calls for improved performance.

    Existing applications can also be executed in kernel mode but do not come with
    the mentioned safety guarantees.
    This is made possible by adding a new branch to the system call invocaion multiplexer
    that invokes system calls with direct function calls \cite{maeda2003}.
    The multiplexer executes additional instructions to invoke the system call however, 
    so this mechanism is not optimal but still sudiciently fast compared to regular system call
    invokation.

  \subsection{Lupine Linux}
    Lupine Linux tries to achive unikernel-like performance and benefits in Linux.
    This is achieved through, one, specialization by using the existing Kconfig 
    configuration mechanism of the Linux kernel, 
    and two, system call overhead elimination using KML.

    For specialisation only 283 of the 15,953 Kconfig configuration options where
    selected as a base configuration \cite{kuo20}.
    With a total of 19 different additional options the top 20 most popular cloud applications,
    determined through Dockerhub download numbers, could all be succesfully executed.

    In benchmarks Lupine Linux outperformed AWS Firecracker's MicroVM, a lightweight 
    kernel image for general cloud application. 
    Lupine Linux also outperformed OSv \cite{osv}, 
    one the POSIX-like unikernels used for reference \cite{kuo20}.

\section{Approach}\label{sec:approach}
  \subsection{Goals}\label{sec:goals}
    The goal of UKL is similar to that of Lupine Linux, in that it aims
    to bring the benefits promised by unikernels to the Linux kernel.
    UKL tries to achieve this while one, maintaining the rich support for hardware devices of Linux.
    Two, UKL aims at retaining the compatability with existing legacy software for the Linux kernel.
    And three, UKL want to preserve the ecosystem of tools for testing and debugging the kernel.
    Preserving this ecosystem and keeping the changes to the Linux kernel als minimal as possible
    would also increase the chance of UKL to be accepted by Linux community.
    As mentioned in \refsec{sec:categories-of-unikernels}, manually porting updates from
    the Linux kernel to UKL would require a continious effort.
    To get around this the authors of UKL aim to have UKL included in the upstream Linux kernel
    \cite{ukl-redhat-post}.

    In a previous paper \cite{raza19} the authors of the UKL paper \cite{raza23}
    observed that applications that require high-performance IO use frameworks
    to bypass the kernel and gain unimpeded access to hardware devices \cite{raza19}.
    This combined with the promised benefits of unikernels creates a need to act
    for the Linux community in order to stay dominant for cloud computing, according to the authors.
    The goal of UKL is to provide the proof that Linux can be adapted to suit the new demands of
    cloud computing and retain its dominant position in the world of modern cloud computing.

  \subsection{Incremental approach}
    UKL follows a so-called incremental approach. 
    Each increment is less general purpose but can bring performance benefits.
    The lowest increment is the base model which perserves almost all the 
    invariants and assumptions of applications written for Linux.
    The performance benefit of the base model is negligible.
    After the application runs on the base model the developer can choose to try different
    configuration options for a higher performance improvement.
    These configuration options might not work with every application, but are easy to try out
    with just a recompilation.
    For more perfomance improvement the developer can choose to modify the application, exploiting the
    knowledge about the application to invoke kernel functionality directly.

  \subsection{Base model}\label{sec:base-model}
    In the base model an application is compiled and statically linked with both 
    the UKL kernel and a modified version of glibc to create a bootable image.
    When executed this image will have a UKL-optimised process executing the supplied 
    application in kernel mode.
    Although in kernel mode the UKL-optimised process is still executed differently to kernel code,
    with transition code to access kernel routines and dynamic non-pinned stacks in user-space.
    The UKL-optimised process is per default also fully preemptable.

    Different to most other unikernels, in UKL regular user-level processes are still possible.
    This is crucial to support debugging and testig tools and initialization scripts needed by
    some applications (see \refsec{sec:goals}).
    User-level processes are however not protected from the UKL-optimised one.
    This is in line with the security model of unikernels where all work that has to 
    be protected is isolated through the hypervisor (\refsec{sec:thread-model}).

    \subsubsection{Address space layout}
      Most unikernels have a single address space due to their single process nature.
      UKL differs in that it retains the split of the virtual address space into kernel and user-space.
      For the UKL-optimised process the code and data segments move to kernel space because
      the application and the kernel are compiled and linked together.
      All other memory regions of the UKL-optimised process remain in user-space.

      This layout could be problematic for applications with large initialized data sections
      that are pinned in UKL due to being in kernel-space.
      According to the authors of the UKL-paper changing this layout would have required changes
      to the Linux kernel that may be difficult to upstream (see \refsec{sec:goals}).

      The virtual address space of regular user-level processes remains unchanged from
      the classic Linux virtual address space layout.

    \subsubsection{Transition on system calls}\label{sec:transition}
      The way regular user-level processes access kernel functionality remains unchanged in UKL.
      The UKL-optimised process also still undergoes the regular entry and exit code of
      the Linux kernel when accessing kernel functionality.
      This code includes changing the execution stack to a kernel stack, scheduling and signal handling.
      The only difference to the transition compared to Linux is that the UKL-optimised process uses
      \code{call} instead of \code{syscall} to jump into the entry code and \code{ret} instead
      of \code{sysret} or \code{iret} to return from the exit code. 
      The differences in behaviour between \code{call} and \code{syscall} and 
      \code{ret} and \code{sysret} are handled through a new system call entry point, 
      \code{ukl\_entry\_syscall\_64}, that is used by the UKL-optimised process.
      Figure \ref{fig:ukl-transition} gives a graphic overwiev.

      \begin{figure*}[hbt]
        \centering
        \includesvg[inkscapelatex=false, width=.75\textwidth]{fig/entry-exit}
        \caption{Transition between applications and kernel in UKL base model}
        \label{fig:ukl-transition}
      \end{figure*}

  \subsection{Configuration options}\label{sec:configuration-options}
    The UKL-paper lists and describes configuration options to bypass the entry and exit code
    on system calls (\code{UKL\_BP}), minimize the amount of stack switches performed 
    by executing user and kernel code on the same stack (\code{CONFIG\_UKL\_SAME\_STACK}),
    and use a regular \code{ret} instruction instead of \code{iret} to return from 
    interrpts (\code{CONFIG\_UKL\_USE\_RET}).
    These configuration options are described by the authors as examples to demonstrate the concept
    and evaluate the performance gain.

  \subsection{Application modification}\label{sec:application-modification}
    In addition to the configuration options a developer can explore more specialised optimisations
    by modifing the application.
    These optimisations are typically based on knowledge about the specific application.
    For example, if an application only uses TCP, a write to a socket will always be to
    a TCP socket.
    By calling the \code{tcp\_sendmsg} routine directly the TCP/UDP polymorphism in the kernel
    can be bypassed.
    
    UKL offers a per-thread flag that causes the thread to be treated like a kernel thread.
    By setting this flag a thread on a performance critical path can avoid preemption
    until its task is completed.

  \subsection{Implementation}
    The current implementation of UKL only supports x86-64 architectures.
    The authors of the UKL-paper hope that communities interested in non-x86 architectures
    will take on porting UKL to their platforms if UKL is accepted upstream.

    \subsubsection{Base model}\label{sec:imp:base-model}
      As mentioned in \refsec{sec:transition}, the usage of \code{call} instead of \code{syscall}
      changes a kernel invariant and thus additional code is needed to resolve that.
      This is done in the new \code{ukl\_entry\_syscall\_64} entry point, which is called by
      UKL application code.
      The return address for system calls is stored in \code{rcx} register which is then 
      pushed to the kernel stack.
      The \code{call} instruction stores the return address on the user stack.
      The authors' solution to this problem is to simply update the return address on the kernel
      stack with the value stored on the user stack \cite{ukl-github-entry}.

      In the entry/exit code the execution mode of the calling thread has to be considered,
      because the UKL-optimised application always executes in kernel mode (see \refsec{sec:base-model}).
      The kernel tracks the execution mode through the \code{CS} register.
      To track the execution mode of UKL threads the authors of the UKL paper added a 
      new per-thread variable \code{in\_user} \cite{ukl-github-entry, ukl-github-inuser-add}.

      \textbf{Entry code:}
      If \code{in\_user} is zero then the calling thread is a regular non-UKL 
      user-level thread \cite{ukl-github-inuser-getter-setter}.
      In this case the kernel just executes the system call without any UKL modification.

      If \code{in\_user} is two then the calling thread is a UKL thread executing 
      user code \cite{ukl-github-inuser-getter-setter}.
      Since the thread is a UKL thread it executes in kernel mode and thus the value of the 
      \code{CS} register was \code{KERNEL\_CS}.
      This value was pushed to the kernel stack in the \code{ukl\_entry\_SYSCALL\_64} entry point.
      In order for the thread to be treated like a user-level thread this stored \code{CS} 
      value has to be changed to the user \code{CS} value.
      The \code{in\_user} value is then set to one because the thread is now executing kernel code.

      If \code{in\_user} is one then the calling thread is a UKL thread executing 
      kernel code cite{ukl-github-inuser-getter-setter}.
      Since the thread is a UKL-optimised it executes in kernel mode and thus the \code{CS} value
      stored on stack is already correct (\code{KERNEL\_CS}).
      The \code{in\_user} value is also already correct.

      \textbf{Exit code:}
      If \code{in\_user} is zero, then the thread is a user-level non-UKL thread and should return
      without any modification.

      If \code{in\_user} is one, then the thread is a UKL thread and should thus remain in 
      kernel mode execution.
      However a regular \code{iret} would take the thread back to user mode.
      To avoid that the \code{CS} value saved on stack is changed to \code{KERNEL\_CS}.
      Then \code{in\_user} is set to two, because the thread is now returning to user code.

    \subsubsection{Bypassing entry/exit code}
      In order not to explode the volume of this report I will only describe the implementation
      of the \code{UKL\_BP} configuration option, used to bypass the entry and exit code
      on system calls.

      As mentioned in \refsec{sec:application-modification} a UKL-optimized application can
      always call the internal system call function directly without going through the entry and
      exit code.
      Since the entry and exit code is, among other things, responsible for basic system services,
      such as RCU handling, switching the execution stack to a kernel stack, scheduling and signal
      handling, bypassing the entry and exit code can result in a faster system call.

      For the bypass the authors of UKL modified the \code{SYSCALL\_DEFINE} macro to add
      a wrapper function named \code{ukl\_bp\_<syscall name>} to each system call \cite{ukl-github-bypass}.
      In glibc the authors added a check to call this wrapper function 
      directly if bypassing is enabled \cite{ukl-glibc-bypass}.
      If bypassing is disabled the regular UKL syscall entry point is used (see \refsec{sec:imp:base-model}).
      
      Bypassing the entry and exit code also bypasses the stack switch from user to kernel stack and back.
      If the configuration option to avoid stack switches (see \refsec{sec:configuration-options}) is
      turned on, then this is not a problem.
      Otherwise a stack switch should occur.
      To achieve that, the authors created functions to conduct a stack switch from user to kernel stack 
      or from kernel to user stack.
      These stack switch functions are then used in the system call wrapper function created earlier, 
      given that the \code{CONFIG\_UKL\_SAME\_STACK} is turned off \cite{ukl-github-bypass}.

      Bypassing the entry and exit code can create a performance benefit, because the book keeping
      (RCU handling, scheduling, signal handling) usually done by the kernel on a system call is also
      bypassed.
      Since this book keeping has to be performed at some point, the authors of UKL added a configurable
      limit for how often the entry/exit code is bypassed before going through the regular entry 
      and exit code \cite{ukl-github-bypass}.
      Setting this limit low will grant less performance benefit but but the book keeping is performed
      more frequent.
      Setting the limit higher can lead to a greater performance gain, but the tail latency for system 
      calls might increase because a backlog of book keeping that has to be done can build 
      up \cite{ukl-github-bypass}.

\section{Conclusion}\label{sec:conclusion}
  \subsection{Performance}
    The UKL paper focuses on runtime performance.
    Other benefits demonstrated by other unikernel research, such as security, boot time or
    resource utilization, are neither targeted nor evaluated.
    
    \subsubsection{System call overhead elemination}
      The authors of the UKL paper compared unmodified Linux to the UKL base model
      and the UKL base model with \code{UKL\_BP} enabled with \code{getppid}, \code{read},
      \code{write}, \code{sendto} and \code{recvfrom} system calls.
      The base performance is evaluated with 1 Byte payloads for \code{read},
      \code{write}, \code{sendto} and \code{recvfrom}.
      Here the performance improvement using the base model is below 5\%.
      The authors credit this to the high degree of optimization of the \code{syscall}
      instruction.
      Using the \code{UKL\_BP} optimization however reaches a performance benefit of
      83\% for \code{getppid} and 49\% for \code{read}, indicating that the entry
      and exit code is the main source of Linux system call latency \cite{raza23}.

      With 8KB payloads for \code{read}, \code{write}, \code{sendto} and \code{recvfrom}
      the performance improvement of the base model becomes negligible. 
      The base model with \code{UKL\_BP} enabled however still achieves a performance 
      improvement of between 11\% for \code{write} and 22\% for \code{recvfrom}.

    \subsubsection{Realistic workloads}
      Further benchmarks were performed by the authors using Redis, a widely used single-threaded 
      in-memory database and Memcached, a multi-threaded key-value store.

      Across all tests the UKL base model a negligible or no performance benefit,
      showing that just replacing \code{syscall} instructions with procedure calls
      gives no real benefit for real workloads.

      The UKL base model with both \code{UKL\_BP} and \code{CONFIG\_UKL\_USE\_RET}
      (see \refsec{sec:configuration-options}) turned on delivered a small performance
      benefit with 12\% throughput improvement for Redis on a physical machine.

  \subsection{Reception by the Linux community}
    The UKL base model was posted as a request for comment (RFC) to the public Linux linux
    kernel mailing list in October 2022 \cite{ukl-rfc-lwn}.
    All exept one responses to the post were of productive nature, with technical questions
    and suggestions. 
    Only one response concerned the inclusion of UKL into the upstream Linux kernel 
    \cite{ukl-rfc-negative}.
    The comment sais that UKL tries to turn Linux into a completely new OS, while expecting 
    the Linux kernel community to carry the support burden and concludes that enormous
    justification would be required to include UKL in the upstream Linux kernel.

    A post by Red Hat Research \cite{ukl-redhat-post} says that UKL aims to "allow 
    the entire upstream Linux developer community to maintain and develop the code".
    This can be seen to confirm the fear of the Linux kernel maintainer mentioned earlier
    \cite{ukl-rfc-negative}.

    Additionaly the trust in Red Hat has dropped after they announced to paywall the
    source code for Red Hat Enterprise Linux (RHEL) \cite{redhat-fuckup}.

    Considering all of this, I do not think UKL will be included in the upstream
    Linux kernel.

  \subsection{Shortcomings of UKL}
    The optimisations for system call overhead elimination and entry/exit code bypassing
    are based on system call being issued by the modified version of glibc, that
    the application and the kernel are compiled with.
    For some languages, like Go, this is a problem, since most system call invocations
    are done directly by the language runtime and not through glibc \cite{ukl-vs-unicraft}.
    This means that Go applications can not benefit from any of the optimisations UKL offers,
    except for application modification.
    This issue is not addressed in the UKL paper.

\bibliographystyle{plain}
\bibliography{template}
%\footnotesize
\end{document}
